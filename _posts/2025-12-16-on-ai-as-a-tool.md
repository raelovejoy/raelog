---
layout: post
title: "On AI as a tool"
summary: AI as 'cognitive scaffolding,' not replacement
---

AI is a loaded topic right now, and for good reason. It raises real questions about labor, authorship, bias, power, and responsibility. Because I use AI in my writing, I want to be clear about how and why—without hype, and without pretending the concerns do not exist.

This is not a defense of AI. It is an explanation of my relationship to it.

## What AI is for me

I use AI as a cognitive tool.

More specifically, I use it to:
- Clarify half-formed thoughts
- Stress-test ideas and arguments
- Organize long notes, logs, or drafts
- Surface counterpoints I might miss
- Improve clarity, accessibility, or structure

I do not treat it as an authority, an author, a friend, or a decision-maker. It is closer to a whiteboard, a notebook, or a very patient interlocutor than a replacement for thinking.

The final responsibility for what I write—claims, tone, ethics, and intent—is always mine.

## Accessibility, ADHD, and executive function

This part matters enough to say explicitly.

AI has become an essential accessibility tool for me in navigating ADHD-related executive dysfunction and overwhelm. Not because it thinks for me, but because it reduces friction at the points where my brain reliably stalls.

It helps with:
- Starting when initiation feels impossible
- Breaking overwhelming tasks into workable steps
- Holding context when my working memory drops it
- Externalizing (not outsourcing) thoughts when everything feels tangled
- Regaining momentum without burning out

In this sense, it functions as scaffolding rather than automation. Similar to calendars, reminders, spellcheck, or other assistive tools, it helps me stay engaged with my own thinking instead of getting stuck before it can take shape. Not that I have a problem with writer's block. On the contrary, the only 'blockage' I have is the overwhelm of words I press into my keyboard.

This is not about productivity for its own sake, but being able to participate, reflect, and create without being derailed by cognitive overload.

## Local AI and self-hosted systems

I am also increasingly interested in local AI and locally hosted systems over the long term.

Part of this is practical—privacy, reliability, and the ability to understand and control the tools I rely on. Part of it is philosophical. I am wary of over-centralized infrastructure, opaque systems, and dependencies that quietly shape behavior without consent.

Exploring local models and self-hosted setups is a way of:
- Reducing reliance on centralized platforms
- Keeping sensitive data closer to where it is created
- Better understanding the constraints and tradeoffs of these systems
- Treating AI as software I work with, not a service I defer to

This interest does not change the boundaries described elsewhere in this post. Whether a system is local or remote, the same principles apply: I remain responsible for the output, the intent, and the consequences.

This is a direction I am actively learning toward, not a claim of having solved it.

## What AI is not for me

Some boundaries matter, especially now.

- AI does not replace thoughts or judgment.
- AI does not get credit for authorship.
- AI does not excuse errors or harm.
- AI output is edited heavily, reshaped, or discarded.

If something appears here, it is because I chose it, stood by it, and took responsibility for it.

## On the controversy

Many criticisms of AI are valid.

There are serious concerns about:
- Exploitation of labor and creative work
- Bias embedded in training data
- Environmental and energy costs
- Centralization of power and infrastructure
- The erosion of trust and authorship norms

Acknowledging these issues does not require pretending AI does not exist, nor does using AI require ignoring them. My approach is conscious, limited use paired with transparency—not blind adoption or evangelism.

## Why I am transparent about this

Tools shape thinking. That has always been true—language, writing, printing, search engines, and software all do this. Pretending otherwise does not protect integrity; it obscures it.

I disclose AI use because transparency matters more than purity tests. Readers can judge the work on its merits, with full context.

If a piece is unclear, wrong, or harmful, the responsibility is still mine.

## A closing note

I am not interested in outsourcing thought, creativity, or responsibility. I am interested in tools that help me think more clearly, write more accessibly, and engage with my own ideas without unnecessary barriers.

This is how I currently use AI. That may change. If it does, I will say so.