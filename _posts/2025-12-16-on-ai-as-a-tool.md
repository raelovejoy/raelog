---
layout: post
title: "On AI as a tool"
summary: AI as 'cognitive scaffolding,' not replacement
---

AI is a loaded topic right now. I’m aware of that. I still use it, and because I write a lot, I don’t want that to be vague or implied or quietly hidden in the background.

This isn’t a defense of AI, but rather me being explicit about how it fits into my process.

For me, AI is a tool. Not an author, not an authority, not a friend, not a stand-in for judgment. More like a whiteboard that talks back, or a place to dump too many thoughts at once and see what survives.

I mostly use it to clarify things that already exist in my head but haven’t landed cleanly yet. To test an idea from a few angles. To reorganize notes that have grown faster than I can hold them. To make writing clearer, more accessible, and less tangled than it would otherwise be.

Clarity is the point. I write constantly, and the goal isn’t speed or volume—it’s saying what I actually mean.

That’s also where accessibility comes in.

I have ADHD, and executive dysfunction is a real constraint in how I work. Not in a dramatic way—just in the accumulation of friction. Starting is hard. Holding context is hard. Knowing where to begin when everything feels equally urgent is hard.

AI helps at those points. Not by thinking for me, but by lowering the threshold where my brain tends to stall. It helps me externalize thoughts when they’re all competing for attention at once. It helps me regain momentum without burning myself out trying to brute-force my way through overwhelm.

I don’t really get writer’s block. If anything, I have the opposite problem—too many words pressing forward at the same time. This is one way I create enough structure to work with that instead of against it.

I’m also increasingly interested in local AI and self-hosted systems, longer term. Partly for practical reasons—privacy, reliability, understanding what I’m actually relying on—and partly because I’m wary of how centralized and opaque a lot of this infrastructure has become.

I’d rather treat AI as software I work with than a service I defer to. Exploring local models is a way of learning where the limits actually are, and what tradeoffs I’m making, instead of abstracting all of that away behind an API.

None of that changes the basic boundaries.

AI doesn’t replace my judgment. It doesn’t get credit for authorship. It doesn’t excuse mistakes or harm. Anything that ends up here is here because I chose it and take responsibility for it.

There are plenty of valid criticisms of AI—about labor, bias, energy use, power, authorship, all of it. Acknowledging those concerns doesn’t require pretending the tools don’t exist, and using the tools doesn’t require pretending the concerns aren’t real. For me, the only workable approach is limited, conscious use paired with transparency.

That’s why I’m explicit about this.

Tools shape thinking. They always have. Language does. Writing does. Software does. I’d rather make that visible than pretend it isn’t happening.

If something I write is unclear, wrong, or harmful, that’s on me. The presence of AI doesn’t change that.

This is how I’m using it right now. That may change. If it does, I’ll say so.
